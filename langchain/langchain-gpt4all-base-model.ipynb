{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LangChain** (Use GPT4All Model)\n",
    "\n",
    "*This notebook was created on **22/07/2024** using python 3.12 version.*\n",
    "\n",
    "Use LangChain library to load a GPT4All model used on a local PC loaded from a specific folder and asking a simple question.\n",
    "\n",
    "##### Remark\n",
    "\n",
    "Before running this tutorial is suggested to read the previous Jupyter Notebooks:\n",
    "\n",
    "1. gpt4all-model-list.ipynb\n",
    "2. gpt4all-base-model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-community==0.2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# set model path and name\n",
    "model_path = Path().home() / \".data\" / \"model\"\n",
    "if not model_path.exists():\n",
    "    raise Exception(f\"The path '{model_path}' does not exists!\")\n",
    "\n",
    "model_name = \"gpt4all-falcon-newbpe-q4_0.gguf\"\n",
    "model_path_name = model_path / model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.gpt4all import GPT4All\n",
    "\n",
    "# load gpt4all model\n",
    "model = GPT4All(model = str(model_path_name))\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is Milan?\n",
      "\n",
      "Milan is a city in the Lombardy region of Italy, located on the Po River.\n"
     ]
    }
   ],
   "source": [
    "# ask question (same as 'gpt4all-base-model.ipynb')\n",
    "question = \"Where is Milan?\"\n",
    "print(question)\n",
    "\n",
    "response = model.generate(prompts = [question])\n",
    "print(response.generations[0][0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312gpt4all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
